---
title: python 处理中文遇到的编码问题总结 
date: 2018-06-07 17:28:30
tags:
- Python
categories: Python
description: 总结Python中最头痛的中文编码问题
---
UnicodeDecodeError: 'utf8' codec can't decode byte 0xxx in position 

 这个错误是因为你代码中的某个字符串使用了费ascii编码的字符，也就是它代表的16进制的编码超过127。 解决这个问题可以使用下面的方法解决，其实就是设置默认的编码。python 2.x的默认编码是ascii，如果改为utf-8，就可以了。

其实从python 3.0以后默认就用utf-8，就没有这个问题了。

### 一、编码知识

1. pyhton的所有内置库、方法接受的是unicode编码的字符串。 
2. str.decode 函数就是转成unicode编码，所以能decode的字符串传级python的内置库、函数都能正确运行。 
3.  3.问题在于这个decode函数解码时到底要传哪个参数：utf-8,gbk,gb2312......等N种编码。参数不当，就会抛类似异常：

 UnicodeDecodeError: 'gbk' codec can't decode bytes in position 2-3: illegal multibyte sequence

UnicodeDecodeError: 'utf8' codec can't decode bytes in position 0-1: invalid data

### 二、内部原因分析

#### 2.1 Python内部字符串的编码

字符串在Python内部的表示是unicode编码，因此，在做编码转换时，通常需要以unicode作为中间编码，即先将其他编码的字符串解码（decode）成unicode，再从unicode编码（encode）成另一种编码。 

decode的作用是将其他编码的字符串转换成unicode编码，如str1.decode('gb2312')，表示将gb2312编码的字符串str1转换成unicode编码。

 encode的作用是将unicode编码转换成其他编码的字符串，如str2.encode('gb2312')，表示将unicode编码的字符串str2转换成gb2312编码。

<u>因此，转码的时候一定要先搞明白，字符串str是什么编码，然后decode成unicode，然后再encode成其他编码。代码中字符串的默认编码与代码文件本身的编码一致。</u>

unicode(str,'gb2312')与str.decode('gb2312')是一样的，都是将gb2312编码的str转为unicode编码 

#### 2.2 文件编码对字符串的影响

 如：s='中文'

如果是在utf8的文件中，该字符串就是utf8编码，如果是在gb2312的文件中，则其编码为gb2312。这种情况下，要进行编码转换，都需要先用decode方法将其转换成unicode编码，再使用encode方法将其转换成其他编码。通常，在没有指定特定的编码方式时，都是使用的系统默认编码创建的代码文件。

如果一个字符串已经是unicode了，再进行解码则将出错，因此通常要对其编码方式是否为unicode进行判断：

```
isinstance(s, unicode) #用来判断是否为unicode
```

 #### 2.3 如何获得系统的默认编码？

```
 #!/usr/bin/env python
 #coding=utf-8
 import sys
 print sys.getdefaultencoding()
```

该段程序在英文WindowsXP上输出为：ascii 

#### 2.4 IDE显示出错的原因

在某些IDE中，字符串的输出总是出现乱码，甚至错误，其实是由于IDE的结果输出控制台自身不能显示字符串的编码，而不是程序本身的问题。 

 如在UliPad中运行如下代码：

```
 s=u"中文"
 print s
```

 会提示：UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)。这是因为UliPad在英文WindowsXP上的控制台信息输出窗口是按照ascii编码输出的（英文系统的默认编码是ascii），而上面代码中的字符串是Unicode编码的，所以输出时产生了错误。

 将最后一句改为：print s.encode('gb2312')则能正确输出“中文”两个字。

若最后一句改为：print s.encode('utf8') 则输出：\xe4\xb8\xad\xe6\x96\x87，这是控制台信息输出窗口按照ascii编码输出utf8编码的字符串的结果。 

### 三、如何判断字符str的编码是什么？ 

使用 chardet  可以很方便的实现字符串/文件的编码检测。尤其是中文网页，有的页面使用GBK/GB2312，有的使用UTF8，如果你需要去爬一些页面，知道网页编码很重要的，虽然HTML页面有charset标签，但是有些时候是不对的。那么chardet就能帮我们大忙了。 

```
>>> import urllib
>>> rawdata = urllib.urlopen('http://www.google.cn/').read()
>>> import chardet
>>> chardet.detect(rawdata)
{'confidence': 0.98999999999999999, 'encoding': 'GB2312'}
```

chardet可以直接用detect函数来检测所给字符的编码。函数返回值为字典，有2个元数，一个是检测的可信度，另外一个就是检测到的编码 。

### 四、程序处理规范

补充：str() 函数将对象转化为适于人阅读的形式。 

对于unciode 类型来说，对他执行一次 str() 相当于执行unciode.encode("utf-8") 无论是在linux还是在windows （有待验证）

Py2.x中：

```
import sys
reload(sys)
sys.setdefaultencoding('utf-8')
所有的字符都用str(处理)
```

输出包治百病？（有待验证）

```
# -*- coding: UTF-8 -*- 
#!/usr/bin/env python 
#coding=utf-8 
s="中文" 
if isinstance(s, unicode):  
    print s.encode('gb2312') 
else: 
    print s.decode('utf-8').encode('gb2312')
```

