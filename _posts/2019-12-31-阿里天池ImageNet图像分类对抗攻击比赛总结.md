---
layout: post
title: 阿里天池 ImageNet 图像分类对抗攻击比赛总结（持续更新）
date: 2019-12-31 23:59
tags:
- comp
- AI
categories: AI
description: 阿里天池ImageNet图像分类对抗攻击比赛总结（持续更新）
---


持续 26 天的阿里天池比赛让我获益匪浅。本来去年我还是一个专业的安全研究人员，但是从今年春天开始就不断探索安全技术和 AI 技术的交叉领域，这种对交叉领域的tan不仅仅保持了对学习的极高的热情，还能够对AI的相关领域有着新的认识。

非常开心能够和伙伴一起钻研 26 天的AI对抗技术。按照我的笔记统计浏览过71篇论文或者往届的解题报告，通读了26篇重要的论文，精读了9篇在这次比赛中起关键上分的论文。不得不说虽然我是第一次接触这个方向的比赛，但是我觉得自己非常热爱这个领域！

这段时期基本就是天天熬夜，一醒来就考虑改善算法，下午调参，顺便错过吃饭，相当有规律~

解决这次比赛主要有二种思路，一个是基于模型的，真正有点AI意思的方式；另一种是基于规则的，使用简单的python程序就可以搞定的方式。

一般来说，这类AI比赛很多时候规则真的都比模型好使，我们使用规则直接取得了第五名的成绩：

![](https://saferman.github.io/assets/img/tianchi_imagenet_adversarial_comp/排行榜.png)

赛后也知道前面的大部分选手都是用规则上分的，后期我们并没有继续改进规则的方式，虽然能上分但是总觉得缺少学习的乐趣，自己还是更想钻研算法，毕竟有希望能在未来发表该领域的论文。

通过模型的方法只取得了第28名的成绩。我觉得这次比赛之所以模型表现如此差在于和过去的多个AI对抗比赛不同，这次主办方使用了三个最先进的(state-of-the-art)防御技术，严重降低了模型攻击技术的效果！

有多严重呢，请看我们复现往届类似比赛冠军的算法的成绩（进入前十至少得是1.0以上）：

- NIPS *2017 AI 对抗*性攻防竞赛冠军清华大学同学的 M-I-FGSM 算法：得分 0.13，排名倒数
- 2018 CAAD 对抗比赛冠军算法优化的 M-FGSM：得分0.24，排名倒数
- 阿里上半年IJCAI的人脸识别对抗算法，我们改进为适合这次比赛的代码：得分0.28，排名倒数

这还只是无目标攻击的得分，在有目标攻击中不仅没有成功，还使得无目标攻击的效果下降。赛后也问了出题人，这次比赛的防御缺少比较 diao，他们都没有特别有效的攻击思路。

让我欣慰的是，即使在如此困难的题目约束下，我和我的队友抱着想研读论文改进算法（想之后发paper）的目的，从多个维度将我们的模型攻击效果逐步提升，下图是从提交记录中绘制的我们模型得分趋势：

![](https://saferman.github.io/assets/img/tianchi_imagenet_adversarial_comp/trend.png)

这次比赛是完全黑盒场景（还有三个防御技术），只能使用完全黑盒攻击的技术（连查询黑盒攻击技术都很难实施），或者使用白盒模型攻击技术但是需要极大地提高迁移能力。下面我总结一下在这次比赛中提升白盒模型攻击技术的 tricks。

### 基础模型的选择

模型融合能够极大地提高白盒攻击的迁移能力，特别是网络结构不同的那些模型。这次比赛我们主要使用 torch 实现的，经过尝试如下四种预训练模型融合的得分最高：

```
resnet_model, vgg19_model, inception_v3_model , inceptionresnetv2_model
```

融合的位置在 logits（softmax前），我的权重参数是都是1/4。之所以选择在 softmax 前融合参考的是这篇论文的实验结论：

> Dong, Yinpeng & Pang, Tianyu & Su, Hang & Zhu, Jun. (2019). Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks. 

AI 对抗领域一个非常有效的防御方式就是讲攻击图片作为训练集给模型训练提高模型对这类攻击的防御能力，比如截止目前为止网络上公开的经过大量 Imagenet 攻击样本预训练的鲁棒性模型如下：

> - sample_defenses/adv_inception_v3/` - adversarially trained Inception v3 model from [Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236) paper.
>
> - `sample_defenses/ens_adv_inception_resnet_v2/` - Inception ResNet v2 model which is adversarially trained against an ensemble of different kind of adversarial examples. Model is described in [Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/abs/1705.07204) paper.
>
> - ImageNet classifier with state-of-the-art adversarial robustness：<https://github.com/facebookresearch/ImageNet-Adversarial-Training/issues/7>--Code and models for the paper [Feature Denoising for Improving Adversarial Robustness](https://arxiv.org/abs/1812.03411), CVPR 2019.
>
>   > Trained on **128 GPUs**, our ImageNet classifier has 42.6% accuracy against an extremely strong **2000-steps white-box** PGD targeted attack. This is a scenario where no previous models have achieved more than 1% accuracy.

大家常用的主要是这三个：

- ens3-adv-Inception-v3 (Inc-v3ens3)
- ens4-adv-Inception-v3 (Inc-v3ens4)
- ens-adv-InceptionResNet-v2 (IncRes-v2ens)

将鲁棒性的防御模型和正常的预训练模型融合作为白盒攻击的模型对提升攻击的迁移能力非常有效（这些预训练的模型都是 tensorflow 版本的）。这次因为时间问题没有使用第三个号称在 128 块 GPU 训练的防御模型。

这次比赛一个不足的点是我们的程序架构最初是我设计的，因为队员都擅长 torch所以用 torch 写的整个比赛代码。但是

### 数据增强

提升白盒攻击迁移能力的核心就是防止本地的白盒攻击过拟合，数据增强是AI对抗比赛中非有效的提分方案。这次比赛的后期的模型上分主要靠这个。下面列举我们这次比赛尝试过的数据增强手段，并且根据测试得分给出一些评价：

- ImageNet 图像预处理

  ```
  mean = [0.485,  0.456, 0.406]
  std = [0.229, 0.224, 0.225]
  ```

- rescaling and padding

- rotate

- lightening

- darkening

- adding Gaussian noise

- translation of image

- jpeg compression

- feature squeezing

- image augumentation

- flip

- scaler change

- gaussian filter

- 离散余弦变换滤波

在这部分推荐几个比较好用的库：

1. 一个针对 numpy image 处理的库 scipy.ndimage
2. [Image augmentation for machine learning experiments —— imgaug](https://github.com/aleju/imgaug)
3. [https://github.com/mdbloice/Augmentor —— Augmentor](https://github.com/mdbloice/Augmentor)

### 模型融合

### 初始化噪声选择

### 高斯模糊

### 损失函数改进

### Dropout

### 重要的论文梳理





