---
layout: post
title: 一次 MySQL 数据大数据处理引发的总结
date: 2019-04-17 14:38
tags:
- mysql
- python
- bigdata
categories: bigdata
description: 一次实践总结
---


事情是这样的，7000 万+的数据，需要读取一些字段，给不同的字段种类打上一个索引数字。只要这些字段有一个不同就属于不同的类别。这个问题看起来真的很简单，但是第一次做这种工作的时候真的快把我搞崩溃了，遇到了很多很多玄学问题。下面会将自己遇到的问题、解决办法以及学到的知识做一个总结。

最近做了三四个工作都是千万级别的数据处理，有流量的，也有数据库的，还有纯文本的。希望自己在这条路上能越走越熟练 ~

### 遇到的问题

1. 数据库字段出现乱码，在 Python 中引发 Unicode Error
2. 数据库字段存在 SQL 注入
3. MySQL 执行 SQL 出现内存错误，内存池过小
4. MySQLdb 普通游标缓存耗时长，内存消耗大；流式游标存活时间短
5. 插入操作较多，耗时较大
6. 给不同种类建立数字索引，需要消耗大量储存空间维持种类表
7. Python 出现循环引用的内存消耗问题和被生命周期更长的变量引用的内存消耗问题；
8. 需要设计和考虑 Ctrl+C 和出错后续处理的问题
9. select 语句执行缓慢

### 解决问题的方法

1. 数据库字段出现乱码，在 Python 中引发 Unicode Error

   对于这种数据我们讨论后直接 pass，这类乱码都是中文导致的。需要进行编码设置解决这个问题。


2. 数据库字段存在 SQL 注入

   在 Python 程序中执行 execute 的时候使用参数的形式：

   ```python
   sql = "select id,uri from mytable where user=%s and age = %s"
   params = ["Saferman", 100]
   db.execute(sql, params)
   ```

   这种方法可以抵御一部分防止 SQL 注入的原因是在 execute 中会对 params 的值进行转义，具体的细节可以查阅源码，这里就不做讨论。

3. MySQL 执行 SQL 出现内存错误，内存池过小

   在 MySQL 命令行界面执行如下语句扩大缓存空间为 40G

   ```sql
   show global variables like 'innodb_buffer_pool_size';
   set global innodb_buffer_pool_size=40*1024*1024*1024; # G - MB - KB
   ```

4. MySQLdb 普通游标缓存耗时长，内存消耗大；流式游标存活时间短

   普通游标在执行 SQL 语句的时候，会将结果全部缓存下来然后继续执行。当数据较大的时候需要在执行 SQL 语句等待很长时间，可以使用流式游标，这个游标不会缓存任何东西，这样就可以继续执行了：

   ```python
   import MySQLdb
   import MySQLdb.cursors
   # 打开数据库连接
   db = MySQLdb.connect(" 服务器 ", "root", " 密码 ", " 数据库 ", charset='utf8', cursorclass = MySQLdb.cursors.SSCursor)
   # 使用 cursor() 方法获取操作游标
   cursor = db.cursor()
   sql = "select uri,id,dip,dport from {};".format(table_name)
   cursor.execute(sql)
   # -------------------
   while True:
       data = cursor.fetchone()
       if data==None:
           break
   # -------------------
   for row in cursor:
       print(row)
   ```

   因为 SSCursor 是没有缓存的游标，这里有几条约束：

   - 这个 connection 只能读完所有行之后才能处理其他 sql。
   - 每次读取后处理数据要快，不能超过 60 s，否则 mysql 将会断开这次连接：也可以修改 [SET NET_WRITE_TIMEOUT = xx](https://link.jianshu.com/?t=http://dev.mysql.com/doc/refman/5.0/en/server-system-variables.html#sysvar_net_write_timeout) 来增加超时间隔。

5. 插入操作较多，耗时较大

   一次性插入较多的数据可以大大减少处理时间，但是相应的需要消耗内存存放这些带插入的数据。

   ```sql
   INSERT INTO `table1` (`field1`, `field2`) VALUES ("data1", "data2"),
                                                    ("data1", "data2"),
                                                    ("data1", "data2"),
                                                    ("data1", "data2"),
                                                    ("data1", "data2");
   ```

6. 给不同种类建立数字索引，需要消耗大量储存空间维持种类表

   关于这个问题，我尝试过三种方法，最好的就是后文会提及的最佳实践

   - 直接放入字典

     ```puyjon
     d = {}
     index = dip + ":" + dport+" " + uri
     try:
         d[index]
     except KeyError：
         d[index] = len(d) + 1
     ```

     最开始的时候我企图将所有的数据读出来，但是 d 消耗的空间太大

   - hash 后放入字典

     将 index 进行一次 hash 处理，因为 index 一般远远超过 32 个字符，所以 hash 后可以缩短长度，但是很可能出现碰撞的问题，这个还可以接受

   - 按照顺序建立索引

     在我们从数据库读取数据的时候限定 distinct 关键字，使得读取出来的每条数据 dip，dport，uri 三者是唯一的，这样只需要按照读取的结果顺序建立索引即可；之后需要知道每一类涉及的原本数据的 id 执行查询语句即可。
     
     ```sql
     select distinct dip,dport,uri from mytable
     ```

     有没有直接 SQL 语句就可以实现这个索引建立的方法，一直没查到 ~ 要是以后发现了再补充 ~


7. Python 出现循环引用的内存消耗问题和被生命周期更长的变量引用的内存消耗问题；

   这部分涉及到《Python 内存优化》和《Python 内存回收机制》的知识，之后会专门总结。

   可以参考本次最佳实践的方法。关键点就是：

   - 使用 gc 库
   - 使用函数代替单纯地 for 循环，结合 limit 语句将只有一次 db 连接的操作分为多次 db 连接建立。

8. 需要设计和考虑 Ctrl+C 和出错后续处理的问题

   这是为了保证程序在调试和出错之后能够保存一些执行成功的数据，或者清理不必要的资源。

   即使有错误处理，也强烈建议将错误打印出来！

   ```python
   except Exception as e:
       print(e)
   ```

9. SQL 语句执行缓慢

   增加 where 的条件和使用 limit 有助于提高速度。

### 解决本次问题的最佳实践

```python
# encoding:utf-8
import MySQLdb
import MySQLdb.cursors
import datetime
import json
import gc


def handle(start, number):
    table_name = " 表名 "
    # 打开数据库连接
    db = MySQLdb.connect(" 数据库地址 ", "root", " 密码 ", " 数据库名字 ", charset='utf8')
    cursor = db.cursor()
    sql = "select distinct dip,dport,uri from {} limit {},{}".format(table_name,start,number)
    cursor.execute(sql)
    d = []
    data = cursor.fetchall()
    if data == () or data == (()):
        return -1
    for dip,dport,uri in data:
        try:
            # Unicode 问题和 SQL 注入问题都在这排除
            sql = 'select id from {} where dip="{}" and dport ="{}" and uri="{}"'.format(table_name, dip, dport, uri)
            cursor.execute(sql)
            d.append(cursor.fetchall())
        except Exception as e:
            print(e)
            d.append(())
    db.close()
    with open('ID-%d.json' % start, 'w') as outfile:
        json.dump(d, outfile)
    del d,db,cursor
    gc.collect()

if __name__ == '__main__':
    start = 0
    number = 100000
    print datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    while True:
        if handle(start,number)==-1:
            break
        start += number
        print "[+]finish %d : " % start,
        print datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
```

这段代码时间里索引和 id 值得表，一行一个索引和一个 id 值。性能瓶颈在 select 和读写文件，看看以后能不能优化一下。此外这段代码其实是由 SQL 注入隐患的。

### SQL 技巧

1. group by + 聚合函数 实现分组操作

   http://www.runoob.com/sql/sql-groupby.html

2. 用户变量

   https://blog.csdn.net/JesseYoung/article/details/40779631

3. 在 MySQL 中实现 sql server 的 row_number() 功能——一个自增变量

   https://www.cnblogs.com/Gin-23333/p/5630720.html

4. 自动递增序列——主键

   https://www.yiibai.com/sql/sql-using-sequences.html

5. SQL 复杂操作常见的关键字

   - union

   - left join\right join

   - limit

   - group by 

   - order by

   - case when

     https://stackoverflow.com/questions/25674737/mysql-update-multiple-rows-with-different-values-in-one-query/25674827

   - 聚合函数

6. 本次最佳实践中，我发现一种非常好的方法，可惜 MySQL 的内存实在不够，无法完成第二步的索引建立

   首先先建立 dip、dport 的索引表：

   ```sql
   CREATE TABLE IF NOT EXISTS ServiceIndex (
            service_type int not null PRIMARY KEY AUTO_INCREMENT,
            dip VARCHAR(20),
            dport VARCHAR(10),
            table_name VARCHAR(30)
             );
   INSERT INTO ServiceIndex (dip, dport, TABLE_NAME) select distinct dip,dport,' 表名 ' from 表名 ;
   ```

   第二步，建立 dip、dport、uri 的索引，其中的 service_type 字段来自上述表，page_type 来自自增字段：

   ```sql
   CREATE TABLE IF NOT EXISTS PageIndex (
            page_type int not null PRIMARY KEY AUTO_INCREMENT,
            service_type int,
            dip VARCHAR(20),
            dport VARCHAR(10),
            uri text,
            table_name VARCHAR(30)
             );
   INSERT INTO PageIndex (dip, dport, uri, TABLE_NAME,service_type) select distinct @dip:=dip,@dport:=dport,uri,' 表名 ',(select service_type from ServiceIndex where dip=@dip and dport=@dport limit 1) from 表名 ;
   ```

   @dip:=dip 是在定义变量；这里解决 sql 注入的隐患可以考虑 to_base64 函数。

7. select 语句本身优化方案：

   https://www.ibm.com/support/knowledgecenter/zh/SSZLC2_7.0.0/com.ibm.commerce.admin.doc/refs/rsdperformanceworkspaces_dup.htm

8. 多表查询，提速方法：

   https://opensource.com/article/17/5/speed-your-mysql-queries-300-times

### MySQL 处理大数据的缺点，和处理大数据常用的方案

1. MySQL 没有一个强大的聚焦内存的搜索引擎
2. 不利用处理高度易失数据
3. 最初设计就是单点系统，不是现在的分布式模型
4. 不是针对大量数据运行复杂查询而设计的

处理大数据经常听到的有：hadoop、spark、Hbase （读的性能比较强)、Elasticsearch